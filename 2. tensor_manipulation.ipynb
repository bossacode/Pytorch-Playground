{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Views\n",
    "\n",
    "https://pytorch.org/docs/stable/tensor_view.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base tensor: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "view tensor: tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "same data memory: True\n",
      "base tensor: tensor([100,   1,   2,   3,   4,   5,   6,   7,   8,   9])\n",
      "view tensor: tensor([[100,   1,   2,   3,   4],\n",
      "        [  5,   6,   7,   8,   9]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(10)\n",
    "M = t.view(2,5)\n",
    "\n",
    "print('base tensor:', t)\n",
    "print('view tensor:', M)\n",
    "\n",
    "print('same data memory:', t.data_ptr() == M.data_ptr())    # view tensor shares the same underlying data with its base tensor. \n",
    "\n",
    "M[0,0] = 100    # Modifying view tensor changes base tensor as well\n",
    "print('base tensor:', t)\n",
    "print('view tensor:', M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contiguous tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mt contiguous: False\n",
      "Mt2 contiguous: True\n",
      "--------------------------------------------------\n",
      "tensor Mt:\n",
      " tensor([[0, 4],\n",
      "        [1, 5],\n",
      "        [2, 6],\n",
      "        [3, 7]])\n",
      "tensor Mt2:\n",
      " tensor([[0, 4],\n",
      "        [1, 5],\n",
      "        [2, 6],\n",
      "        [3, 7]])\n",
      "--------------------------------------------------\n",
      "Mt storage:  0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 8]\n",
      "Mt2 storage:  0\n",
      " 4\n",
      " 1\n",
      " 5\n",
      " 2\n",
      " 6\n",
      " 3\n",
      " 7\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 8]\n"
     ]
    }
   ],
   "source": [
    "M = torch.arange(8).reshape(2,4)\n",
    "Mt = M.t()\n",
    "Mt2 = Mt.contiguous()   # enforce copying data when `Mt` is not contiguous to get contiguous tensor\n",
    "\n",
    "print('Mt contiguous:', Mt.is_contiguous())\n",
    "print('Mt2 contiguous:', Mt2.is_contiguous())\n",
    "print('-' * 50)\n",
    "\n",
    "print('tensor Mt:\\n', Mt)\n",
    "print('tensor Mt2:\\n', Mt2)   # same data\n",
    "print('-' * 50)\n",
    "\n",
    "print('Mt storage:', Mt.storage())\n",
    "print('Mt2 storage:', Mt2.storage())    # layout changed to make tensor contiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view()\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.Tensor.view.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M contiguous: True\n",
      "same memory: True\n"
     ]
    }
   ],
   "source": [
    "M = torch.randn(2,4)\n",
    "M_view = M.view(4,2)\n",
    "\n",
    "print('M contiguous:', M.is_contiguous())\n",
    "print('same memory:', M.data_ptr() == M_view.data_ptr())    # view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mt contiguous: False\n",
      "same memory: True\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m Mt_view \u001b[39m=\u001b[39m Mt\u001b[39m.\u001b[39mview(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m)  \u001b[39m# in this case, view is created although Mt is not contiguous\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msame memory:\u001b[39m\u001b[39m'\u001b[39m, M\u001b[39m.\u001b[39mdata_ptr() \u001b[39m==\u001b[39m Mt_view\u001b[39m.\u001b[39mdata_ptr())\n\u001b[0;32m----> 8\u001b[0m \u001b[39mprint\u001b[39m(Mt\u001b[39m.\u001b[39;49mview(\u001b[39m2\u001b[39;49m,\u001b[39m4\u001b[39;49m))    \u001b[39m# cannot create view\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "Mt = M.t()  # .t() returns view\n",
    "\n",
    "print('Mt contiguous:', Mt.is_contiguous())\n",
    "\n",
    "Mt_view = Mt.view(2,2,2)  # in this case, view is created although Mt is not contiguous\n",
    "print('same memory:', M.data_ptr() == Mt_view.data_ptr())\n",
    "\n",
    "Mt.view(2,4)    # cannot create view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshape()\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.reshape.html\n",
    "\n",
    "    returns view if possible, else returns copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same memory: True\n"
     ]
    }
   ],
   "source": [
    "M = torch.randn(2,4)\n",
    "M_reshape = M.reshape(4,2)\n",
    "\n",
    "print('same memory:', M.data_ptr() == M_reshape.data_ptr())     # view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same memory: False\n"
     ]
    }
   ],
   "source": [
    "Mt = M.t()  # .t() returns view\n",
    "Mt_reshape = Mt.reshape(2,4)\n",
    "\n",
    "print('same memory:', M.data_ptr() == Mt_reshape.data_ptr())    # copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# permute()\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.permute.html#torch.permute\n",
    "\n",
    "    returns view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor M shape: torch.Size([2, 3, 5])\n",
      "tensor M shape after permute: torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "M = torch.randn(2, 3, 5)\n",
    "\n",
    "print('tensor M shape:', M.size())\n",
    "print('tensor M shape after permute:', M.permute(2,0,1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transpose()\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose\n",
    "\n",
    "    returns view if input is strided tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor M shape: torch.Size([2, 3, 5])\n",
      "tensor M shape after transpose: torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "M = torch.randn(2, 3, 5)\n",
    "\n",
    "print('tensor M shape:', M.size())\n",
    "print('tensor M shape after transpose:', M.transpose(0,1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T\n",
    "\n",
    "    returns view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor M shape: torch.Size([2, 3, 5])\n",
      "tensor M shape after T: torch.Size([5, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "M = torch.randn(2, 3, 5)\n",
    "\n",
    "print('tensor M shape:', M.size())\n",
    "print('tensor M shape after T:', M.T.size())    # equivalent to M.permute(n-1, n-2, ..., 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mT\n",
    "\n",
    "    returns view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor M shape: torch.Size([2, 3, 5])\n",
      "tensor M shape after mT: torch.Size([2, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "M = torch.randn(2, 3, 5)\n",
    "\n",
    "print('tensor M shape:', M.size())\n",
    "print('tensor M shape after mT:', M.mT.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# squeeze() / unsqueeze()\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.squeeze.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.unsqueeze.html\n",
    "\n",
    "    returns view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor M shape: torch.Size([3, 1, 2, 1, 4])\n",
      "tensor M shape after squeeze: torch.Size([3, 2, 4])\n",
      "tensor M shape after squeeze of given dim: torch.Size([3, 2, 1, 4])\n",
      "tensor M shape: torch.Size([3, 1, 2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "M = torch.randn(3,1,2,1,4)\n",
    "\n",
    "print('tensor M shape:', M.shape)\n",
    "print('tensor M shape after squeeze:', M.squeeze().shape)\n",
    "print('tensor M shape after squeeze of given dim:', M.squeeze(dim=1).shape)\n",
    "print('tensor M shape:', M.shape)   # doesn't change original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor M shape: torch.Size([3, 2, 4])\n",
      "tensor M shape after unsqueeze: torch.Size([3, 1, 2, 4])\n",
      "tensor M shape: torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "M = torch.randn(3,2,4)\n",
    "\n",
    "print('tensor M shape:', M.shape)\n",
    "print('tensor M shape after unsqueeze:', M.unsqueeze(dim=1).shape)\n",
    "print('tensor M shape:', M.shape)   # doesn't change original tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split()\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.split.html#torch.split\n",
    "\n",
    "    returns view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5643, -1.7106,  0.4178],\n",
       "         [-0.5787,  1.6969, -1.0581],\n",
       "         [ 0.6216, -0.3524,  1.4452],\n",
       "         [ 1.5583,  0.2216,  0.8427]]),\n",
       " tensor([[-0.3251,  0.2625, -0.9964],\n",
       "         [ 1.6694, -0.3952,  0.5485],\n",
       "         [-0.4208,  1.3071,  0.4308],\n",
       "         [ 1.0798, -0.7649,  0.1510]]),\n",
       " tensor([[-0.4081,  0.2047, -0.1016],\n",
       "         [-0.3021, -0.1500,  0.0825]]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.randn(10,3)\n",
    "\n",
    "M.split(4, dim=0)    # split size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0736, -0.3137, -0.2389]]),\n",
       " tensor([[ 0.5531, -1.6912, -0.7959],\n",
       "         [-0.8158,  0.1184, -1.0938],\n",
       "         [-1.5594,  2.0082, -0.5666],\n",
       "         [-0.0358, -1.0796, -1.0379]]),\n",
       " tensor([[ 0.5899, -1.0051, -0.3351],\n",
       "         [-0.8898,  1.0382,  1.1405],\n",
       "         [ 0.5793, -0.5514,  1.3916],\n",
       "         [ 0.2950, -0.6828,  0.7144],\n",
       "         [ 0.6035, -0.8606, -0.2066]]))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.randn(10,3)\n",
    "\n",
    "M.split([1,4,5], dim=0)    # split section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunk()\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.chunk.html#torch.chunk\n",
    "\n",
    "    returns view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2341, -1.7935,  0.2225],\n",
       "         [-0.8964, -0.3458, -0.9920],\n",
       "         [ 0.1107, -2.5733,  0.7776]]),\n",
       " tensor([[ 0.3252, -2.0168,  1.3477],\n",
       "         [-0.1625, -0.1699, -0.0067],\n",
       "         [ 2.7201,  0.1987, -1.7251]]),\n",
       " tensor([[ 1.0358,  1.9285,  0.4576],\n",
       "         [ 1.3377,  0.8691, -1.6527],\n",
       "         [ 0.2574, -1.0060,  0.1165]]),\n",
       " tensor([[1.0916, 0.0541, 1.2650]]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.randn(10,3)\n",
    "\n",
    "M.chunk(4, dim=0)   # number of chuncks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stack()\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.stack.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor M shape: torch.Size([3, 4])\n",
      "tensor N shape: torch.Size([3, 4])\n",
      "tensor t shape: torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "M = torch.randn(3,4)\n",
    "N = torch.randn(3,4)\n",
    "\n",
    "t = torch.stack((M, N), dim=0)\n",
    "\n",
    "print('tensor M shape:', M.shape)\n",
    "print('tensor N shape:', N.shape)\n",
    "print('tensor t shape:', t.shape)   # makes new dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cat()\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.cat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor M shape: torch.Size([3, 4])\n",
      "tensor N shape: torch.Size([3, 4])\n",
      "tensor t shape: torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "M = torch.randn(3,4)\n",
    "N = torch.randn(3,4)\n",
    "\n",
    "t = torch.cat((M, N), dim=0)\n",
    "\n",
    "print('tensor M shape:', M.shape)\n",
    "print('tensor N shape:', N.shape)\n",
    "print('tensor t shape:', t.shape)   # concatenated along dim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
